# Copyright 2025 Thousand Brains Project
# Copyright 2022-2024 Numenta Inc.
#
# Copyright may exist in Contributors' modifications
# and/or contributions to the work.
#
# Use of this source code is governed by the MIT
# license that can be found in the LICENSE file or at
# https://opensource.org/licenses/MIT.

import copy
import os

import torch


class OnlineOptimizationDatasetMixin:
    """Use this mixin to overwrite __getitem__ to return data and its transformed copy.

    This mixin overwrites __getitem__ to return a piece of data, and a transformed copy
    of this piece of data.

    In the init it defines the ways in which the data will be transformed, and calls
    super to instantiate the parent class. There is no parent class unless this class
    is used in the context of a mixin, so it will not work on its own.

    Example::

        class ModelNet40OnlineOptimization(OnlineOptimizationDatasetMixin, ModelNet40):
            pass

    Note:
        The order of classes in the mixin defined in the above example matters!
        OnlineOptimizationDataset must come first, as its __init__method calls
        super and instantiates ModelNet40.

    See Also:
        tbp.monty.frameworks.experiments.online_optimization

    """

    def __init__(self, **kwargs):
        """Initialize the dataset.

        Args:
            **kwargs: Keyword arguments.
                dst_transform: transform to be applied to the target object, eg sampling
                    k points from the mesh
                src_transform: transform to be applied to the source object, eg sampling
                    k points from the mesh, and then rotating translating

        Note:
            kwargs are used so the parent class can be instantiated, so kwargs
            must also contain all parameters for the mixed in parent class
        """
        super().__init__(**kwargs)
        self.dst_transform = kwargs["dst_transform"]
        self.src_transform = kwargs["src_transform"]

    def __getitem__(self, idx):
        """Apply src and dst transforms to the data and return.

        Note:
            Transforms like SamplePoints sample different points at each call.
            Thus, src and dst may belong to the same underlying object, but may
            represent different samples in addition to transforms like rotations
            or translations.

        Returns:
            src: The source object.
            dst: The destination object.
            label: The label.
        """
        # transforms are in-place and thus are not idempotent
        data_src = copy.deepcopy(self.data[idx])
        data_dst = copy.deepcopy(self.data[idx])
        src = self.src_transform(data_src)
        dst = self.dst_transform(data_dst)
        label = self.get_obj_name(self.labels[idx])

        return src, dst, label


class OnlineOptimizationExactCopyMixin(OnlineOptimizationDatasetMixin):
    """Version of the parent class where the src transformation is applied to dst.

    A verions of the parent class, but where the src transformation is applied to
    dst itself. Thus, if dst_transform includs SamplePoints, dst will be a fixed point
    cloud and src will then rotate / translate / shear / etc. the exact same points.

    Note:
        Whereas OnlineOptimizationDatasetMixin applies separate transforms to the
        same piece of data, this class applies the transforms in sequence. Thus,
        for a transform like SamplePoints which returns different data on each
        call, the previous class will return two different point clouds, with one
        transformed, whereas this class will return two identical point clouds,
        with one transformed.
    """

    def __getitem__(self, idx):

        # transforms are in-place and thus are not idempotent
        data_dst = copy.deepcopy(self.data[idx])
        dst = self.dst_transform(data_dst)
        dst_copy = copy.deepcopy(dst)
        src = self.src_transform(dst_copy)
        label = self.get_obj_name(self.labels[idx])

        return src, dst, label


class OnlineOptimizationDatasetFromMonty:
    """Use this dataset for simulating inference in an embodied Monty system.

    This dataset is intended for developing better inference algorithms.

    To use, first run an embodied experiment. At inference time, a sequence of
    observations will be generated by the policy. This collection of data points
    generated at inference time is referred to as the path. These will be saved and
    returned by this dataset. The sequence of inference points
    Example:
        `python ./benchmarks/run.py -e camera_patch_multi_object`

    Next, run a script (in development) to copy the object models and the paths to a
    location, searched for by this dataset.

    Example:
        `python ./benchmarks/run_to_dataset.py -e camera_patch_multi_object \
            -d path_to_where_dataset_is_saved`

    Finally, pass this dataset as the dataset_class to an OnlineOptimizationExpeirment
    config, and set the arguments to be path_to_where_dataset_is_saved.
    """

    def __init__(self, root, transform=None, target_transform=None):

        self.root = root

        self.idx_to_model = torch.load(os.path.join(self.root, "idx_to_model.pt"))
        self.idx_to_path = torch.load(os.path.join(self.root, "idx_to_path.pt"))
        self.idx_to_target = torch.load(os.path.join(self.root, "idx_to_target.pt"))

        self.transform = transform
        self.target_transform = target_transform

    def __getitem__(self, idx):

        target = self.idx_to_target[idx]
        model = self.idx_to_model[idx]
        path = self.idx_to_path[idx]

        if self.transform:
            path = self.transform(path)

        if self.target_transform:
            target = self.target_transform(target)

        return path, model, target

    def __len__(self):
        return len(self.idx_to_target)
